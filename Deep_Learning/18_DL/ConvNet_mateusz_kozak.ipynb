{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers, initializers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "import os\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models_homework')\n",
    "model_name = \"ConvNet_without_PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r\"/home/mateusz/Desktop/18_dl/fashion-mnist_train.csv\")\n",
    "test_data = pd.read_csv(r\"/home/mateusz/Desktop/18_dl/fashion-mnist_test.csv\")\n",
    "\n",
    "train_data = train_data.sample(frac=1)\n",
    "test_data = test_data.sample(frac=1)\n",
    "\n",
    "scaller = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateusz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/mateusz/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data[train_data.columns[1:]]\n",
    "y_train = train_data[train_data.columns[0]]\n",
    "\n",
    "#x_train = scaller.fit_transform(x_train)\n",
    "\n",
    "x_test = test_data[test_data.columns[1:]]\n",
    "y_test = test_data[test_data.columns[0]]\n",
    "\n",
    "\n",
    "##output encoding\n",
    "encoder = OneHotEncoder()\n",
    "y_train = encoder.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "y_test = encoder.fit_transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "## reshaping and making data from 0 to 1\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = np.array(x_train).reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "\n",
    "x_test = np.array(x_train).reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_train.astype('float32')\n",
    "x_test /= 255\n",
    "\n",
    "##model params\n",
    "params ={\n",
    "    \"input_shape\" : input_shape,\n",
    "    \"classes\" : y_train.shape[1],\n",
    "    \"learning_rate\" : 0.0115,\n",
    "    \"dropout_rate\" : 0.1,\n",
    "    \"logs\" : \"/home/mateusz/Desktop/18_dl/logs\",\n",
    "    \"epochs\" : 30\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model creation\n",
    "\n",
    "def create_convnet(params):\n",
    "    model = Sequential()\n",
    "    \n",
    "    #first layer\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\",\n",
    "                     input_shape=(params[\"input_shape\"])))\n",
    "    #model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(params[\"dropout_rate\"]))\n",
    "    \n",
    "    ##second layer + maxpool\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), activation='relu', padding=\"same\"))\n",
    "    #model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(params[\"dropout_rate\"]))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), activation='relu', padding=\"same\"))\n",
    "    #model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(params[\"dropout_rate\"]))\n",
    "    \n",
    "    \n",
    "    ##Flatten layer\n",
    "    model.add(Flatten())\n",
    "    ##Dense\n",
    "    model.add(Dense(64, activation=\"relu\", kernel_initializer = 'random_uniform',\n",
    "                bias_initializer='zeros'))\n",
    "    model.add(Dropout(params[\"dropout_rate\"]))\n",
    "    model.add(Dense(128, activation=\"relu\", kernel_initializer = 'random_uniform',\n",
    "                bias_initializer='zeros'))\n",
    "    model.add(Dropout(params[\"dropout_rate\"]))\n",
    "    model.add(Dense(64, activation=\"relu\", kernel_initializer = 'random_uniform',\n",
    "                bias_initializer='zeros'))\n",
    "    model.add(Dropout(params[\"dropout_rate\"]))\n",
    "    model.add(Dense(params[\"classes\"], activation=\"softmax\"))\n",
    "    \n",
    "    ##compile\n",
    "    optimizer = RMSprop(lr=params[\"learning_rate\"], decay=5e-3/params[\"epochs\"])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['categorical_accuracy', \"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0831 23:53:40.588973 140470288582464 deprecation_wrapper.py:119] From /home/mateusz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0831 23:53:40.606158 140470288582464 deprecation_wrapper.py:119] From /home/mateusz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0831 23:53:40.611244 140470288582464 deprecation_wrapper.py:119] From /home/mateusz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0831 23:53:40.632441 140470288582464 deprecation_wrapper.py:119] From /home/mateusz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0831 23:53:40.644230 140470288582464 deprecation.py:506] From /home/mateusz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0831 23:53:40.794534 140470288582464 deprecation_wrapper.py:119] From /home/mateusz/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0831 23:53:40.800276 140470288582464 deprecation_wrapper.py:119] From /home/mateusz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## model fitting\n",
    "\n",
    "model = create_convnet(params)\n",
    "tensorboard = TensorBoard(log_dir=params[\"logs\"], histogram_freq=0, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 292,490\n",
      "Trainable params: 292,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0831 23:53:41.552275 140470288582464 deprecation.py:323] From /home/mateusz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0831 23:53:42.350422 140470288582464 deprecation_wrapper.py:119] From /home/mateusz/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0831 23:53:42.351233 140470288582464 deprecation_wrapper.py:119] From /home/mateusz/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 2.1743 - categorical_accuracy: 0.2870 - acc: 0.2870 - val_loss: 0.9498 - val_categorical_accuracy: 0.5893 - val_acc: 0.5893\n",
      "Epoch 2/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.9311 - categorical_accuracy: 0.6522 - acc: 0.6522 - val_loss: 0.5865 - val_categorical_accuracy: 0.7485 - val_acc: 0.7485\n",
      "Epoch 3/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.5958 - categorical_accuracy: 0.7734 - acc: 0.7734 - val_loss: 0.4576 - val_categorical_accuracy: 0.8413 - val_acc: 0.8413\n",
      "Epoch 4/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.4815 - categorical_accuracy: 0.8232 - acc: 0.8232 - val_loss: 0.4234 - val_categorical_accuracy: 0.8455 - val_acc: 0.8455\n",
      "Epoch 5/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.4207 - categorical_accuracy: 0.8470 - acc: 0.8470 - val_loss: 0.3640 - val_categorical_accuracy: 0.8659 - val_acc: 0.8659\n",
      "Epoch 6/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.3856 - categorical_accuracy: 0.8603 - acc: 0.8603 - val_loss: 0.3741 - val_categorical_accuracy: 0.8593 - val_acc: 0.8593\n",
      "Epoch 7/25\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.3644 - categorical_accuracy: 0.8675 - acc: 0.8675 - val_loss: 0.3681 - val_categorical_accuracy: 0.8671 - val_acc: 0.8671\n",
      "Epoch 8/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.3468 - categorical_accuracy: 0.8734 - acc: 0.8734 - val_loss: 0.3814 - val_categorical_accuracy: 0.8709 - val_acc: 0.8709\n",
      "Epoch 9/25\n",
      "48000/48000 [==============================] - 99s 2ms/step - loss: 0.3290 - categorical_accuracy: 0.8805 - acc: 0.8805 - val_loss: 0.3349 - val_categorical_accuracy: 0.8849 - val_acc: 0.8849\n",
      "Epoch 10/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.3208 - categorical_accuracy: 0.8849 - acc: 0.8849 - val_loss: 0.3307 - val_categorical_accuracy: 0.8840 - val_acc: 0.8840\n",
      "Epoch 11/25\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.3123 - categorical_accuracy: 0.8879 - acc: 0.8879 - val_loss: 0.3122 - val_categorical_accuracy: 0.8855 - val_acc: 0.8855\n",
      "Epoch 12/25\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.2988 - categorical_accuracy: 0.8927 - acc: 0.8927 - val_loss: 0.3076 - val_categorical_accuracy: 0.8848 - val_acc: 0.8848\n",
      "Epoch 13/25\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.2934 - categorical_accuracy: 0.8947 - acc: 0.8947 - val_loss: 0.3657 - val_categorical_accuracy: 0.8600 - val_acc: 0.8600\n",
      "Epoch 14/25\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.2878 - categorical_accuracy: 0.8969 - acc: 0.8969 - val_loss: 0.3005 - val_categorical_accuracy: 0.8983 - val_acc: 0.8983\n",
      "Epoch 15/25\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.2855 - categorical_accuracy: 0.8965 - acc: 0.8965 - val_loss: 0.2837 - val_categorical_accuracy: 0.8976 - val_acc: 0.8976\n",
      "Epoch 16/25\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.2808 - categorical_accuracy: 0.9007 - acc: 0.9007 - val_loss: 0.2819 - val_categorical_accuracy: 0.8985 - val_acc: 0.8985\n",
      "Epoch 17/25\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.2712 - categorical_accuracy: 0.9015 - acc: 0.9015 - val_loss: 0.2940 - val_categorical_accuracy: 0.8989 - val_acc: 0.8989\n",
      "Epoch 18/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.2687 - categorical_accuracy: 0.9056 - acc: 0.9056 - val_loss: 0.2987 - val_categorical_accuracy: 0.8942 - val_acc: 0.8942\n",
      "Epoch 19/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.2643 - categorical_accuracy: 0.9045 - acc: 0.9045 - val_loss: 0.2791 - val_categorical_accuracy: 0.9037 - val_acc: 0.9037\n",
      "Epoch 20/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.2570 - categorical_accuracy: 0.9077 - acc: 0.9077 - val_loss: 0.2689 - val_categorical_accuracy: 0.9049 - val_acc: 0.9049\n",
      "Epoch 21/25\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.2511 - categorical_accuracy: 0.9111 - acc: 0.9111 - val_loss: 0.2833 - val_categorical_accuracy: 0.9031 - val_acc: 0.9031\n",
      "Epoch 22/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.2477 - categorical_accuracy: 0.9104 - acc: 0.9104 - val_loss: 0.2784 - val_categorical_accuracy: 0.9047 - val_acc: 0.9047\n",
      "Epoch 23/25\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.2500 - categorical_accuracy: 0.9115 - acc: 0.9115 - val_loss: 0.2886 - val_categorical_accuracy: 0.9007 - val_acc: 0.9007\n",
      "Epoch 24/25\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.2422 - categorical_accuracy: 0.9129 - acc: 0.9129 - val_loss: 0.2855 - val_categorical_accuracy: 0.9065 - val_acc: 0.9065\n",
      "Epoch 25/25\n",
      "48000/48000 [==============================] - 89s 2ms/step - loss: 0.2478 - categorical_accuracy: 0.9127 - acc: 0.9127 - val_loss: 0.2903 - val_categorical_accuracy: 0.9070 - val_acc: 0.9070\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    verbose=1, \n",
    "                    epochs=25, \n",
    "                    batch_size=700, \n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /home/mateusz/Desktop/18_dl/saved_models_homework/ConvNet_without_PCA \n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
